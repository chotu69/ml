{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "663c784a-f01a-480f-b158-cc53ab60b179",
   "metadata": {},
   "source": [
    "1)\tImplement a simple linear regression model for the salary.csv dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d31b679-1178-47f4-ba30-87d0df43fc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "data = pd.read_csv('salary.csv')\n",
    "\n",
    "print(data.head())\n",
    "\n",
    "X = data[['months']] \n",
    "y = data['salary']  \n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_train, y_train, color='blue', label='Actual Salary (Training set)')\n",
    "plt.plot(X_train, model.predict(X_train), color='red', label='Regression Line')\n",
    "plt.title('Salary vs Experience in Months (Training set)')\n",
    "plt.xlabel('Months of Experience')\n",
    "plt.ylabel('Salary')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_test, y_test, color='green', label='Actual Salary (Test set)')\n",
    "plt.plot(X_train, model.predict(X_train), color='red', label='Regression Line')\n",
    "plt.title('Salary vs Experience in Months (Test set)')\n",
    "plt.xlabel('Months of Experience')\n",
    "plt.ylabel('Salary')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef55819-8bea-45e8-b546-3354ae30cdaf",
   "metadata": {},
   "source": [
    "2)\tImplement a simple linear regression model for the rent.csv dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f661194d-634b-44e5-9155-ba7762dec9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "data = pd.read_csv('rent.csv')\n",
    "\n",
    "print(data.head())\n",
    "\n",
    "X = data[['month']]\n",
    "y = data['rent']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_train, y_train, color='blue', label='Actual Rent (Training set)')\n",
    "plt.plot(X_train, model.predict(X_train), color='red', label='Regression Line')\n",
    "plt.title('Rent vs Month (Training set)')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Rent')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_test, y_test, color='green', label='Actual Rent (Test set)')\n",
    "plt.plot(X_train, model.predict(X_train), color='red', label='Regression Line')\n",
    "plt.title('Rent vs Month (Test set)')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Rent')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45d6517-c76c-47d9-83fa-072fb66bf7e2",
   "metadata": {},
   "source": [
    "3)\tImplement a simple linear regression model for the sales.csv dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500678d1-659e-423e-82d9-5addb346a6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv('sales.csv')\n",
    "X = data['fahrenheit'].values.reshape(-1, 1)\n",
    "y = data['sales'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_train = model.predict(X_train_scaled)\n",
    "y_pred_test = model.predict(X_test_scaled)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred_test)\n",
    "mse = mean_squared_error(y_test, y_pred_test)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"\\nModel Evaluation Metrics:\")\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")\n",
    "print(f\"RÂ² Score: {model.score(X_test_scaled, y_test):.4f}\")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.scatter(X_train, y_train, color='blue', label='Training Data', alpha=0.5)\n",
    "# Plot test data\n",
    "plt.scatter(X_test, y_test, color='green', label='Test Data', alpha=0.5)\n",
    "\n",
    "X_sorted = np.sort(X)\n",
    "X_sorted_scaled = scaler.transform(X_sorted.reshape(-1, 1))\n",
    "y_pred_sorted = model.predict(X_sorted_scaled)\n",
    "plt.plot(X_sorted, y_pred_sorted, color='red', label='Regression Line')\n",
    "\n",
    "plt.xlabel('Temperature (Fahrenheit)')\n",
    "plt.ylabel('Sales')\n",
    "plt.title('Linear Regression: Sales vs Temperature')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nModel Coefficients:\")\n",
    "print(f\"Slope: {model.coef_[0]:.2f}\")\n",
    "print(f\"Intercept: {model.intercept_:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2aae393-0e73-471c-a582-30b34b1a8932",
   "metadata": {},
   "source": [
    "4)\tImplement a multiple linear regression model for the house.csv dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba5ec94-74ef-4391-b1fc-59eaeac50d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('house.csv')\n",
    "\n",
    "# If the first row is indeed the header, pandas should have recognized it\n",
    "# If not, we can set the column names manually\n",
    "if 'Square_Foot' in data.columns:\n",
    "    data.columns = ['size', 'bedrooms', 'bathrooms', 'year', 'lot_size', 'garage_size', 'neighborhood_quality', 'price']\n",
    "else:\n",
    "    # If pandas didn't recognize the header, we set it manually and skip the first row\n",
    "    column_names = ['size', 'bedrooms', 'bathrooms', 'year', 'lot_size', 'garage_size', 'neighborhood_quality', 'price']\n",
    "    data = pd.read_csv('house.csv', header=None, names=column_names, skiprows=1)\n",
    "\n",
    "# Split features and target\n",
    "X = data.drop('price', axis=1)\n",
    "y = data['price']\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"Root Mean Squared Error: {rmse}\")\n",
    "\n",
    "# Visualizations\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel(\"Actual Price\")\n",
    "plt.ylabel(\"Predicted Price\")\n",
    "plt.title(\"Actual vs Predicted House Prices\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "residuals = y_test - y_pred\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_pred, residuals, alpha=0.5)\n",
    "plt.plot([y_pred.min(), y_pred.max()], [0, 0], 'r--', lw=2)\n",
    "plt.xlabel(\"Predicted Price\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "feature_importance = pd.DataFrame({'feature': X.columns, 'importance': abs(model.coef_)})\n",
    "feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(feature_importance['feature'], feature_importance['importance'])\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Absolute Coefficient Value\")\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd2add2-e42a-4c81-85d5-9565fd96c013",
   "metadata": {},
   "source": [
    "5)\tImplement a multiple linear regression model for the income.csv dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8535a42-267c-4be7-a872-72813341d89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('income.csv')\n",
    "\n",
    "# Split features and target\n",
    "X = data[['age', 'experience']]\n",
    "y = data['income']\n",
    "\n",
    "# i. Data scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# ii. Training and testing of the model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# iii. Create the regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# iv. Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")\n",
    "\n",
    "# v. Visualize the results\n",
    "\n",
    "# Actual vs Predicted plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel(\"Actual Income\")\n",
    "plt.ylabel(\"Predicted Income\")\n",
    "plt.title(\"Actual vs Predicted Income\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Residual plot\n",
    "residuals = y_test - y_pred\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_pred, residuals, alpha=0.5)\n",
    "plt.plot([y_pred.min(), y_pred.max()], [0, 0], 'r--', lw=2)\n",
    "plt.xlabel(\"Predicted Income\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({'feature': X.columns, 'importance': abs(model.coef_)})\n",
    "feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(feature_importance['feature'], feature_importance['importance'])\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Absolute Coefficient Value\")\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3D scatter plot\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "scatter = ax.scatter(X['age'], X['experience'], y, c=y, cmap='viridis')\n",
    "ax.set_xlabel('Age')\n",
    "ax.set_ylabel('Experience')\n",
    "ax.set_zlabel('Income')\n",
    "plt.colorbar(scatter)\n",
    "plt.title('3D Scatter Plot: Age, Experience, and Income')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb031a7-347f-4f4d-9b9c-f5480e05c129",
   "metadata": {},
   "outputs": [],
   "source": [
    "6)\tImplement a logistic regression model for the built-in digits dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f373d9ab-ef1f-413b-8864-be3abbf7a33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the digits dataset\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "# i. Data scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# ii. Training and testing of the model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# iii. Create the regression model\n",
    "base_model = LogisticRegression(max_iter=1000)\n",
    "model = OneVsRestClassifier(base_model)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# iv. Display confusion matrix and classification report\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "\n",
    "# v. Display k-fold cross-validation score\n",
    "cv_scores = cross_val_score(model, X_scaled, y, cv=5)\n",
    "print(\"\\nCross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV score:\", cv_scores.mean())\n",
    "print(\"Standard deviation of CV scores:\", cv_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c1d81e-5e84-4690-b259-2523dcfc20db",
   "metadata": {},
   "outputs": [],
   "source": [
    "7)\tImplement a Support Vector Machine model for the built-in iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59a48b9-1744-4186-9870-440dd32cc973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# i. Data scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# ii. Training and testing of the model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# iii. Create the SVM model\n",
    "model = SVC(kernel='rbf', random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# iv. Display confusion matrix and classification report\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=iris.target_names))\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=iris.target_names, \n",
    "            yticklabels=iris.target_names)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "\n",
    "# v. Display k-fold cross-validation score\n",
    "cv_scores = cross_val_score(model, X_scaled, y, cv=5)\n",
    "print(\"\\nCross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV score:\", cv_scores.mean())\n",
    "print(\"Standard deviation of CV scores:\", cv_scores.std())\n",
    "\n",
    "# Function to plot decision boundaries\n",
    "def plot_decision_boundaries(X, y, ax=None):\n",
    "    model = SVC(kernel='rbf', random_state=42)\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    h = .02  # step size in the mesh\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    \n",
    "    ax.contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.RdYlBu)\n",
    "    scatter = ax.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.RdYlBu, edgecolor='black')\n",
    "    ax.set_xlabel(iris.feature_names[0])\n",
    "    ax.set_ylabel(iris.feature_names[1])\n",
    "    return scatter\n",
    "\n",
    "# Visualize decision boundaries for different feature pairs\n",
    "fig, axs = plt.subplots(3, 2, figsize=(15, 20))\n",
    "feature_pairs = [(0, 1), (0, 2), ( 0, 3), (1, 2), (1, 3), (2, 3)]\n",
    "for i, (ax, pair) in enumerate(zip(axs.flatten(), feature_pairs)):\n",
    "    X_pair = X_scaled[:, pair]\n",
    "    scatter = plot_decision_boundaries(X_pair, y, ax=ax)\n",
    "    ax.set_title(f'Decision Boundaries (Features {pair[0]} and {pair[1]})')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd1c923-334c-4ca8-8639-4342be2c6aef",
   "metadata": {},
   "source": [
    "8)\tImplement a Bagging model for the built-in wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226bab88-621a-4ea8-a053-245732c4e934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the wine dataset\n",
    "wine = load_wine()\n",
    "X, y = wine.data, wine.target\n",
    "\n",
    "# i. Data scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# ii. Training and testing of the model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# iii. Create the Bagging model\n",
    "base_estimator = DecisionTreeClassifier(random_state=42)\n",
    "try:\n",
    "    # For newer versions of scikit-learn\n",
    "    model = BaggingClassifier(estimator=base_estimator, n_estimators=10, random_state=42)\n",
    "except TypeError:\n",
    "    # For older versions of scikit-learn\n",
    "    model = BaggingClassifier(base_estimator=base_estimator, n_estimators=10, random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# iv. Display confusion matrix and classification report\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=wine.target_names))\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=wine.target_names, \n",
    "            yticklabels=wine.target_names)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "\n",
    "# v. Display k-fold cross-validation score\n",
    "cv_scores = cross_val_score(model, X_scaled, y, cv=5)\n",
    "print(\"\\nCross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV score:\", cv_scores.mean())\n",
    "print(\"Standard deviation of CV scores:\", cv_scores.std())\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = np.mean([tree.feature_importances_ for tree in model.estimators_], axis=0)\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, np.array(wine.feature_names)[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c0ddd5-c81d-45c3-85ce-2ffff97f62ba",
   "metadata": {},
   "source": [
    "9) Implement a PCA to visualize the built-in wine dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97afe04d-2484-4d83-b3e7-62e7498d1a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Load the wine dataset\n",
    "wine = load_wine()\n",
    "X = wine.data\n",
    "y = wine.target\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Calculate the explained variance ratio\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "# Plot the cumulative explained variance ratio\n",
    "plt.figure(figsize=(10, 6))\n",
    "cumulative_variance_ratio = np.cumsum(explained_variance_ratio)\n",
    "plt.plot(range(1, len(cumulative_variance_ratio) + 1), cumulative_variance_ratio, 'bo-')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance Ratio')\n",
    "plt.title('Cumulative Explained Variance Ratio vs. Number of Components')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 2D visualization\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = ['r', 'g', 'b']\n",
    "for color, i, target_name in zip(colors, [0, 1, 2], wine.target_names):\n",
    "    plt.scatter(X_pca[y == i, 0], X_pca[y == i, 1], color=color, alpha=.8, lw=2,\n",
    "                label=target_name)\n",
    "plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "plt.title('PCA of Wine Dataset (2 components)')\n",
    "plt.xlabel(f'First Principal Component ({explained_variance_ratio[0]:.2f})')\n",
    "plt.ylabel(f'Second Principal Component ({explained_variance_ratio[1]:.2f})')\n",
    "plt.show()\n",
    "\n",
    "# 3D visualization\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "for color, i, target_name in zip(colors, [0, 1, 2], wine.target_names):\n",
    "    ax.scatter(X_pca[y == i, 0], X_pca[y == i, 1], X_pca[y == i, 2], color=color, alpha=.8,\n",
    "               label=target_name)\n",
    "ax.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "ax.set_title('PCA of Wine Dataset (3 components)')\n",
    "ax.set_xlabel(f'First Principal Component ({explained_variance_ratio[0]:.2f})')\n",
    "ax.set_ylabel(f'Second Principal Component ({explained_variance_ratio[1]:.2f})')\n",
    "ax.set_zlabel(f'Third Principal Component ({explained_variance_ratio[2]:.2f})')\n",
    "plt.show()\n",
    "\n",
    "# Print the explained variance ratio for each component\n",
    "for i, ratio in enumerate(explained_variance_ratio):\n",
    "    print(f\"PC{i+1} explained variance ratio: {ratio:.4f}\")\n",
    "\n",
    "# Print the cumulative explained variance ratio for 2 and 3 components\n",
    "print(f\"\\nCumulative explained variance ratio (2 components): {cumulative_variance_ratio[1]:.4f}\")\n",
    "print(f\"Cumulative explained variance ratio (3 components): {cumulative_variance_ratio[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4dee56-b390-433c-8511-de687cf95cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "10) Implement a Singular Value Decomposition (SVD) on the given input matrix.  Display U matrix, the singular values, and the V transpose matrix. Finally, reconstruct the original matrix and display  the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11abacee-cb88-45e8-931d-134c57b0437b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the input matrix\n",
    "# For this example, let's use a 4x3 matrix\n",
    "A = np.array([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9],\n",
    "    [10, 11, 12]\n",
    "])\n",
    "\n",
    "print(\"Original Matrix A:\")\n",
    "print(A)\n",
    "print()\n",
    "\n",
    "# Perform SVD\n",
    "U, s, Vt = np.linalg.svd(A, full_matrices=False)\n",
    "\n",
    "# Display U matrix\n",
    "print(\"U matrix:\")\n",
    "print(U)\n",
    "print()\n",
    "\n",
    "# Display singular values\n",
    "print(\"Singular values:\")\n",
    "print(s)\n",
    "print()\n",
    "\n",
    "# Display V transpose matrix\n",
    "print(\"V transpose matrix:\")\n",
    "print(Vt)\n",
    "print()\n",
    "\n",
    "# Reconstruct the original matrix\n",
    "# We need to create a diagonal matrix from the singular values\n",
    "S = np.diag(s)\n",
    "\n",
    "# Reconstruct A = U * S * Vt\n",
    "A_reconstructed = np.dot(U, np.dot(S, Vt))\n",
    "\n",
    "print(\"Reconstructed Matrix A:\")\n",
    "print(A_reconstructed)\n",
    "print()\n",
    "\n",
    "# Check if the reconstruction is close to the original\n",
    "if np.allclose(A, A_reconstructed):\n",
    "    print(\"The reconstruction is successful!\")\n",
    "else:\n",
    "    print(\"There might be some numerical differences due to floating-point arithmetic.\")\n",
    "\n",
    "# Calculate and print the difference between original and reconstructed matrices\n",
    "diff = np.abs(A - A_reconstructed)\n",
    "print(\"\\nDifference between original and reconstructed matrices:\")\n",
    "print(diff)\n",
    "print(\"\\nMaximum difference:\", np.max(diff))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
